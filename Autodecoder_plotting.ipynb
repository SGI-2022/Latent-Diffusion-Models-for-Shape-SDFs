{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6928f68f-9ab8-44ea-879b-0699f443424d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load clsses/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3489bac3-f8ae-4883-bafc-194340f9f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "import meshplot as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "import random\n",
    "import math\n",
    "from itertools import chain as chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b488b323-2c81-4797-8f65-006d349f1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChairDataset(Dataset):\n",
    "    def __init__(self, file_paths, n_points_to_load):\n",
    "        self.file_paths = file_paths\n",
    "        self.n_points_per_shape = 50000\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            training_set = np.load(file_path)\n",
    "            assert len(training_set['points']) == self.n_points_per_shape, f\"{self.n_points_per_shape} data points expected, got: {training_set['points']}\"\n",
    "                \n",
    "        self.n_points_to_load = n_points_to_load # number of points to load at once \n",
    "        \n",
    "    def __getitem__(self, shape_idx):        \n",
    "        training_set = np.load(self.file_paths[shape_idx]) # TODO: try mmap_mode='r'\n",
    "        points = training_set['points']\n",
    "        sdfs = training_set['sdf']\n",
    "        \n",
    "        n_shape_idx = np.full((self.n_points_to_load, 1), shape_idx, dtype=int)\n",
    "        \n",
    "        n_rand = random.sample(range(self.n_points_per_shape), self.n_points_to_load) # randomly pick 'n_points_to_load number' of indices  \n",
    "        \n",
    "        n_points = points[n_rand]\n",
    "        \n",
    "        n_sdf = sdfs[n_rand]\n",
    "        n_sdf = np.resize(n_sdf, (self.n_points_to_load, 1))\n",
    "        \n",
    "        return n_shape_idx, n_points, n_sdf\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f4f948-1da7-4473-aa7e-cbc41a92912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(all_file_or_not, n_files = 0):\n",
    "    file_paths = []\n",
    "    main_dir = '../data/03001627_sdfs/'\n",
    "\n",
    "    if all_file_or_not: # loading all files\n",
    "        n_files = 0\n",
    "        for sub_dir in os.scandir(main_dir):\n",
    "            if sub_dir.is_dir():\n",
    "                for file in os.listdir(main_dir + sub_dir.name):\n",
    "                    file_paths.append(main_dir + sub_dir.name + '/' + file) if file.endswith(\"sdf_samples.npz\") else None\n",
    "            n_files += 1\n",
    "            \n",
    "    else: # loading specific # of files\n",
    "        for sub_dir in os.scandir(main_dir):\n",
    "            if sub_dir.is_dir():\n",
    "                for file in os.listdir(main_dir + sub_dir.name):\n",
    "                    file_paths.append(main_dir + sub_dir.name + '/' + file) if file.endswith(\"sdf_samples.npz\") else None\n",
    "            if len(file_paths) == n_files:\n",
    "                break\n",
    "    \n",
    "    print(f'total # of files: {n_files}')\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa72699-7834-4639-9b3a-c3c579f3c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_shapes, shape_code_length, n_inner_nodes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.shape_code_length = shape_code_length\n",
    "        self.shape_codes = nn.Embedding(n_shapes, shape_code_length) # shape code as an embedding\n",
    "        nn.init.normal_(self.shape_codes.weight, mean=0, std=0.01)\n",
    "        \n",
    "        self.linear1 = nn.Linear(3 + shape_code_length, n_inner_nodes) # (x, y, z) + shape code \n",
    "        self.linear2 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear3 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear4 = nn.Linear(n_inner_nodes, n_inner_nodes - (3 + shape_code_length))\n",
    "        self.linear5 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear6 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear7 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear8 = nn.Linear(n_inner_nodes, 1) # output a SDF value\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, shape_idx, x):\n",
    "        shape_code = self.shape_codes(shape_idx.view(1, -1))\n",
    "        shape_code = shape_code.view(-1, self.shape_code_length)\n",
    "        shape_code_with_xyz = torch.cat((x, shape_code), dim=1) # concatenate horizontally\n",
    "        \n",
    "        out = self.linear1(shape_code_with_xyz)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear5(torch.cat((out, shape_code_with_xyz), dim=1)) # skip connection\n",
    "        out = self.relu(out)\n",
    "        out = self.linear6(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear7(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear8(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def add_noise_to_shape_codes(self, beta):\n",
    "        self.shape_codes.weight.data += beta*(torch.rand_like(self.shape_codes.weight) * torch.std(self.shape_codes.weight, unbiased=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6188ca0c-8ad9-468d-b867-d03e52a571f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_points(file_paths, n_points_per_shape, n_points_to_generate):\n",
    "    shape_idx = random.sample(range(len(file_paths)), 1)[0] # pick a shape randomly out of 7000 shapes\n",
    "    n_shape_idx = np.full((n_points_to_generate, 1), shape_idx, dtype=int)\n",
    "    \n",
    "    training_set = np.load(file_paths[shape_idx]) \n",
    "    points = training_set['points']\n",
    "    sdfs = training_set['sdf']\n",
    "\n",
    "    rand = random.sample(range(n_points_per_shape), n_points_to_generate) # pick 1000 points randomly\n",
    "\n",
    "    return torch.from_numpy(n_shape_idx), torch.from_numpy(points[rand]), torch.from_numpy(sdfs[rand])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec57306-69b1-4237-8873-aba7d755db6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of files: 6778\n"
     ]
    }
   ],
   "source": [
    "file_paths = load_files(True)\n",
    "\n",
    "n_points_per_shape = 50000\n",
    "n_points_to_load = 2048  # n_points_to_load= n points loaded at once from a single file\n",
    "batch_size = 10 # batch_size = n shapes loaded in one batch, not n data points\n",
    "dataset = ChairDataset(file_paths=file_paths, n_points_to_load=n_points_to_load)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111fee15-cc5b-48ea-8a40-5de2bbcaef58",
   "metadata": {},
   "source": [
    "#### Plotting inferred shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7cbc9-7023-42e2-ae21-b94136186321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = './models/autodecoder_08052022_073446' # loading one point at a time\n",
    "# model = MLP_old(10, 256, 256)\n",
    "# filename = './models/autodecoder_08122022_202902' # loading multiple points at a time, 8 layers\n",
    "# model = MLP(10, 256, 512)\n",
    "# filename = './models/autodecoder_08122022_234636' # loading multiple points at a time, 3 layers, extra permutation\n",
    "# model = MLP_old(10, 256, 256)\n",
    "# filename = './models/autodecoder_08132022_003242' # loading multiple points at a time, 4 layers, extra permutation, \n",
    "# model = MLP_old(10, 256, 256)\n",
    "# filename = './models/autodecoder_08132022_011401' # loading multiple points at a time, 4 layers, extra permutation, rigor=5 \n",
    "# model = MLP_old(10, 256, 256)\n",
    "# filename = './models/autodecoder_08132022_041952' # loading multiple points at a time, 8 layers, 16 shapes, extra permutation, rigor=5 \n",
    "# model = MLP(16, 256, 512)\n",
    "# filename = './models/autodecoder_08132022_170026' # loading multiple points at a time, 8 layers, 16 shapes, extra permutation, rigor=2, w.o clamping \n",
    "# model = MLP(16, 256, 512)\n",
    "# filename = './models/autodecoder_08132022_190738' # loading 1024 points at a time, 8 layers, 6778 shapes, extra permutation, up to epoch 1813, without clamping\n",
    "# model = MLP(6778, 256, 512)\n",
    "# filename = './models/autodecoder_08142022_121303 # loading 1024 points at a time, 8 layers, 6778 shapes, extra permutation, up to epoch 1813, clamping + L1loss\n",
    "# model = MLP(6778, 256, 512)\n",
    "# 08142022_231250 # tanh, training loss increased\n",
    "# model = MLP(6778, 256, 512)\n",
    "# 08182022_105030 # remove max_norm, initialization only, regularization param: sigma = 1e2\n",
    "# model = MLP(6778, 256, 512)\n",
    "# 08182022_105028 # remove max_norm, initialization only, regularization param: sigma = 1e-2\n",
    "# model = MLP(6778, 256, 512)\n",
    "# 08182022_172451 # rerun on 10 shapes with the most updated network\n",
    "# model = MLP(10, 256, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ea869c-7667-43dc-abdd-a104434c2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "y = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "z = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "P = torch.from_numpy(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19826e7-58e9-436d-a0de-268405bae71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = './models/autodecoder_08182022_200131_28'\n",
    "# model = MLP(6778, 256, 512)\n",
    "# model.load_state_dict(torch.load(filename))\n",
    "# model.eval()\n",
    "\n",
    "# print(model.shape_codes.weight[0][:5])\n",
    "# print(torch.std(model.shape_codes.weight))\n",
    "# model.shape_codes.weight.data=0.1*torch.rand_like(model.shape_codes.weight) * torch.std(model.shape_codes.weight)\n",
    "# print(model.shape_codes.weight[0][:5])\n",
    "                                  \n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f30726-f34e-430b-87a8-1c94a2d54c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulaugguerrero_gmail_com/miniconda3/lib/python3.9/site-packages/jupyter_client/session.py:716: UserWarning: Message serialization failed with:\n",
      "Out of range float values are not JSON compliant\n",
      "Supporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n",
      "  content = self.pack(content)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e41751f8c74b8ea9fff01083fdc9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(48.013362…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e1e6fcac5e4ca18fea3a76aed6755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(52.002223…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e8d24c503940619cb1016531370840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(47.912233…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2037e578eb462db6826ae81d116886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(47.499584…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7ff3ff01eeb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename = './models/autodecoder_08182022_200131_86'\n",
    "filename = './models/autodecoder_08182022_200131_172'\n",
    "\n",
    "\n",
    "model = MLP(6778, 256, 512)\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.eval()\n",
    "\n",
    "shape_idx = 1\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * shape_idx\n",
    "\n",
    "volume = model(shape_idx_tensor,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "shape_idx = 100\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * shape_idx\n",
    "\n",
    "volume = model(shape_idx_tensor,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "shape_idx = 300\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * shape_idx\n",
    "\n",
    "volume = model(shape_idx_tensor,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "shape_idx = 600\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * shape_idx\n",
    "\n",
    "volume = model(shape_idx_tensor,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134bd4ed-deae-4aeb-900f-1a8831a8b2e2",
   "metadata": {},
   "source": [
    "#### plotting ground truth shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86082f1c-a052-4cba-a908-0591866d31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulaugguerrero_gmail_com/miniconda3/lib/python3.9/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float32\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/home/paulaugguerrero_gmail_com/miniconda3/lib/python3.9/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint32\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0060ca2fedf045afbb7e5ce914ccd9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d18344b2cf41f1aaa1db4a9d1998d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c0a0e91aef43e18fbf182967e0d71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2e4c48919840c3be5dbf5aa8c570a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7ff3fee7b100>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_idx = 1\n",
    "mesh = trimesh.load(file_paths[shape_idx].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces, c=np.array([0, 0.9, 0.9]))\n",
    "\n",
    "shape_idx = 100\n",
    "mesh = trimesh.load(file_paths[shape_idx].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces, c=np.array([0, 0.9, 0.9]))\n",
    "\n",
    "shape_idx = 300\n",
    "mesh = trimesh.load(file_paths[shape_idx].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces, c=np.array([0, 0.9, 0.9]))\n",
    "\n",
    "shape_idx = 600\n",
    "mesh = trimesh.load(file_paths[shape_idx].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces, c=np.array([0, 0.9, 0.9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436768dd-2be8-4327-8313-5073c843c3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for shape_idx in range(10):\n",
    "#     mesh = trimesh.load(file_paths[shape_idx].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "#     mp.plot(mesh.vertices, mesh.faces, c=np.array([0, 0.9, 0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2e4ed-b6ba-4f09-bb3c-6ce7fea1877f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
