{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfd3e8e-cf26-448c-a4f6-2f865e16ef28",
   "metadata": {},
   "source": [
    "## Multiprocessing marching cube\n",
    "\n",
    "reference: https://github.com/fogleman/sdf/blob/main/sdf/mesh.py#L26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b88ce-b61a-4bd2-92a6-c7400e718326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from skimage import measure\n",
    "import meshplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34535a6-9acc-43eb-a63a-a092ca960285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere_sdf(p, center=0, radius=1):\n",
    "    return np.linalg.norm(p - center, axis=1) - radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea0aca-1544-452c-aa8c-275f39cb6b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 65939264\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Surface level must be within volume data range.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m verts_combined \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m faces_combined \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m verts, faces \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap(f, batches):\n\u001b[1;32m     52\u001b[0m     faces_combined\u001b[38;5;241m.\u001b[39mextend(np\u001b[38;5;241m.\u001b[39marray(faces) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(verts_combined))\n\u001b[1;32m     53\u001b[0m     verts_combined\u001b[38;5;241m.\u001b[39mextend(np\u001b[38;5;241m.\u001b[39marray(verts))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/multiprocessing/pool.py:870\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m_worker\u001b[0;34m(sdf, job)\u001b[0m\n\u001b[1;32m     20\u001b[0m P \u001b[38;5;241m=\u001b[39m _cartesian_product(X, Y, Z)\n\u001b[1;32m     21\u001b[0m volume \u001b[38;5;241m=\u001b[39m sdf(P)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(X), \u001b[38;5;28mlen\u001b[39m(Y), \u001b[38;5;28mlen\u001b[39m(Z)))\n\u001b[0;32m---> 22\u001b[0m verts, faces, normals, values \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarching_cubes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# verts = verts[faces]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m scale \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([X[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m X[\u001b[38;5;241m0\u001b[39m], Y[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m Y[\u001b[38;5;241m0\u001b[39m], Z[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m Z[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skimage/measure/_marching_cubes_lewiner.py:133\u001b[0m, in \u001b[0;36mmarching_cubes\u001b[0;34m(volume, level, spacing, gradient_direction, step_size, allow_degenerate, method, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"Marching cubes algorithm to find surfaces in 3d volumetric data.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mIn contrast with Lorensen et al. approach [2]_, Lewiner et\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlewiner\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_marching_cubes_lewiner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspacing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mgradient_direction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mallow_degenerate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_classic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlorensen\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _marching_cubes_lewiner(volume, level, spacing,\n\u001b[1;32m    139\u001b[0m                                    gradient_direction, step_size,\n\u001b[1;32m    140\u001b[0m                                    allow_degenerate, use_classic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m                                    mask\u001b[38;5;241m=\u001b[39mmask)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/skimage/measure/_marching_cubes_lewiner.py:177\u001b[0m, in \u001b[0;36m_marching_cubes_lewiner\u001b[0;34m(volume, level, spacing, gradient_direction, step_size, allow_degenerate, use_classic, mask)\u001b[0m\n\u001b[1;32m    175\u001b[0m     level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(level)\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m<\u001b[39m volume\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;129;01mor\u001b[39;00m level \u001b[38;5;241m>\u001b[39m volume\u001b[38;5;241m.\u001b[39mmax():\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurface level must be within volume data range.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# spacing\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(spacing) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Surface level must be within volume data range."
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "WORKERS = multiprocessing.cpu_count()\n",
    "\n",
    "def _cartesian_product(*arrays):\n",
    "    la = len(arrays)\n",
    "    dtype = np.result_type(*arrays)\n",
    "    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
    "    for i, a in enumerate(np.ix_(*arrays)):\n",
    "        arr[...,i] = a\n",
    "    return arr.reshape(-1, la)\n",
    "\n",
    "def _worker(sdf, job):\n",
    "    X, Y, Z = job\n",
    "    # P = np.vstack(np.meshgrid(X,Y,Z)).reshape(3,-1).T\n",
    "    P = _cartesian_product(X, Y, Z)\n",
    "    volume = sdf(P).reshape((len(X), len(Y), len(Z)))\n",
    "    verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "    # verts = verts[faces]\n",
    "    scale = np.array([X[1] - X[0], Y[1] - Y[0], Z[1] - Z[0]])\n",
    "    offset = np.array([X[0], Y[0], Z[0]])\n",
    "    # verts = verts * scale + offset\n",
    "    # verts = verts[faces]\n",
    "    return verts*scale+offset, faces\n",
    "\n",
    "X = np.linspace(-1, 1, 401)\n",
    "Y = np.linspace(-1, 1, 401)\n",
    "Z = np.linspace(-1, 1, 401)\n",
    "\n",
    "batch_size = 101\n",
    "s = batch_size\n",
    "Xs = [X[i:i+s+1] for i in range(0, len(X), s)]\n",
    "Ys = [Y[i:i+s+1] for i in range(0, len(Y), s)]\n",
    "Zs = [Z[i:i+s+1] for i in range(0, len(Z), s)]\n",
    "\n",
    "batches = list(itertools.product(Xs, Ys, Zs))\n",
    "num_batches = len(batches)\n",
    "num_samples = sum(len(xs) * len(ys) * len(zs) for xs, ys, zs in batches)\n",
    "print(num_batches, num_samples)\n",
    "\n",
    "pool = ThreadPool(WORKERS)\n",
    "f = partial(_worker, sphere_sdf) # _worker, sdf callables\n",
    "\n",
    "verts_combined = []\n",
    "faces_combined = []\n",
    "\n",
    "for verts, faces in pool.imap(f, batches):\n",
    "    faces_combined.extend(np.array(faces) + len(verts_combined))\n",
    "    verts_combined.extend(np.array(verts))\n",
    "    \n",
    "    \n",
    "mp.plot(np.array(verts_combined), np.array(faces_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc22af3-9501-4304-a105-4c12b4af3996",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/audodecoder_08052022_073446'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m MLP(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/audodecoder_08052022_073446\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     42\u001b[0m shape_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/audodecoder_08052022_073446'"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "WORKERS = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "# autodecoder MLP class\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_shapes, shape_code_length, n_inner_nodes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.shape_code_length = shape_code_length\n",
    "        self.shape_codes = nn.Embedding(n_shapes, shape_code_length, max_norm=0.01) # shape code as an embedding # TODO: take this outside \n",
    "        self.linear1 = nn.Linear(3 + shape_code_length, n_inner_nodes) # (x, y, z) + shape code \n",
    "        self.linear2 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear3 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear4 = nn.Linear(n_inner_nodes, 1) # output a SDF value\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, shape_idx, x):\n",
    "        shape_code = self.shape_codes(shape_idx.view(1, -1))\n",
    "        shape_code = shape_code.view(-1, self.shape_code_length)\n",
    "        shape_code_with_xyz = torch.cat((x, shape_code), dim=1) # concatenate horizontally\n",
    "        \n",
    "        out = self.linear1(shape_code_with_xyz)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear4(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = MLP(10, 256, 256)\n",
    "model.load_state_dict(torch.load('./models/autodecoder_08052022_073446'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "shape_idx = 0\n",
    "\n",
    "\n",
    "def _cartesian_product(*arrays):\n",
    "    la = len(arrays)\n",
    "    dtype = np.result_type(*arrays)\n",
    "    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
    "    for i, a in enumerate(np.ix_(*arrays)):\n",
    "        arr[...,i] = a\n",
    "    return arr.reshape(-1, la)\n",
    "\n",
    "def _worker(sdf, job):\n",
    "    X, Y, Z = job\n",
    "    # P = np.vstack(np.meshgrid(X,Y,Z)).reshape(3,-1).T\n",
    "    P = _cartesian_product(X, Y, Z)\n",
    "    P = torch.from_numpy(P)\n",
    "    shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * shape_idx\n",
    "    volume = sdf(shape_idx_tensor, P).reshape((len(X), len(Y), len(Z)))\n",
    "    verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "    volume = volume.detach().numpy()\n",
    "    # verts = verts[faces]\n",
    "    scale = np.array([X[1] - X[0], Y[1] - Y[0], Z[1] - Z[0]])\n",
    "    offset = np.array([X[0], Y[0], Z[0]])\n",
    "    # verts = verts * scale + offset\n",
    "    # verts = verts[faces]\n",
    "    return verts*scale+offset, faces\n",
    "\n",
    "X = np.linspace(-1, 1, 201)\n",
    "Y = np.linspace(-1, 1, 201)\n",
    "Z = np.linspace(-1, 1, 201)\n",
    "\n",
    "batch_size = 11\n",
    "s = batch_size\n",
    "Xs = [X[i:i+s+1] for i in range(0, len(X), s)]\n",
    "Ys = [Y[i:i+s+1] for i in range(0, len(Y), s)]\n",
    "Zs = [Z[i:i+s+1] for i in range(0, len(Z), s)]\n",
    "\n",
    "batches = list(itertools.product(Xs, Ys, Zs))\n",
    "num_batches = len(batches)\n",
    "num_samples = sum(len(xs) * len(ys) * len(zs) for xs, ys, zs in batches)\n",
    "print(num_batches, num_samples)\n",
    "\n",
    "pool = ThreadPool(WORKERS)\n",
    "f = partial(_worker, model) # _worker, sdf callables\n",
    "\n",
    "verts_combined = []\n",
    "faces_combined = []\n",
    "\n",
    "for verts, faces in pool.imap(f, batches):\n",
    "    faces_combined.extend(np.array(faces) + len(verts_combined))\n",
    "    verts_combined.extend(np.array(verts))\n",
    "    \n",
    "    \n",
    "mp.plot(np.array(verts_combined), np.array(faces_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2805d0-a311-4530-b2ed-8eb26e071215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
