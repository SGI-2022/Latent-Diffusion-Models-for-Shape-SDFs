{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51826e46-bf48-4fe9-8d2f-0dbfd4df75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "import meshplot as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce864d3-5412-4b6c-a8bc-4f9413f34bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag shape index to each x=xyz, y=sdf\n",
    "# horizontally concatenate for multiple chapes\n",
    "# returns shape index, x=xyz (1 by 3), y=sdf\n",
    "class ChairDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        for idx, file_path in enumerate(file_paths): #TODO: move to getitem\n",
    "            training_set = np.load(file_path)\n",
    "            points = training_set['points']\n",
    "            points = torch.from_numpy(points.astype(np.float32)) #TODO: dypte precision is lost??\n",
    "            idx_tensor = torch.ones((points.shape[0], 1), dtype=torch.int) * (idx) # 0 based indexing shapes\n",
    "            \n",
    "            sdf = training_set['sdf']\n",
    "            sdf = torch.from_numpy(sdf.astype(np.float32)) \n",
    "            sdf = sdf.view(sdf.shape[0], 1)\n",
    "            \n",
    "            n_samples = sdf.shape[0] \n",
    "\n",
    "            if idx == 0:\n",
    "                self.shape_idx = idx_tensor\n",
    "                self.x = points\n",
    "                self.y = sdf\n",
    "                self.n_samples = n_samples\n",
    "            else:\n",
    "                self.shape_idx = torch.cat((self.shape_idx, idx_tensor), dim = 0) # concatenate vertically\n",
    "                self.x = torch.cat((self.x, points), dim = 0) #concatenate vertically\n",
    "                self.y = torch.cat((self.y, sdf), dim = 0) #concatenate vertically\n",
    "                self.n_samples += n_samples\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.shape_idx[index], self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89dc8f-068b-4005-ba8b-08a304a77b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_shapes, shape_code_length, n_inner_nodes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.shape_code_length = shape_code_length\n",
    "        self.shape_codes = nn.Embedding(n_shapes, shape_code_length, max_norm=0.01) # shape code as an embedding # TODO: take this outside \n",
    "        self.linear1 = nn.Linear(3 + shape_code_length, n_inner_nodes) # (x, y, z) + shape code \n",
    "        self.linear2 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear3 = nn.Linear(n_inner_nodes, 1) # output a SDF value\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, shape_idx, x):\n",
    "        shape_code = self.shape_codes(shape_idx.view(1, -1))\n",
    "        shape_code = shape_code.view(-1, self.shape_code_length)\n",
    "        shape_code_with_xyz = torch.cat((x, shape_code), dim=1) # concatenate horizontally\n",
    "        \n",
    "        out = self.linear1(shape_code_with_xyz)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527b3ab-168b-48c2-9651-6855b147afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = 10\n",
    "file_paths = []\n",
    "main_dir = '../data/03001627_sdfs/'\n",
    "for sub_dir in os.scandir(main_dir):\n",
    "    if sub_dir.is_dir():\n",
    "        for file in os.listdir(main_dir + sub_dir.name):\n",
    "            file_paths.append(main_dir + sub_dir.name + '/' + file) if file.endswith(\"sdf_samples.npz\") else None\n",
    "    if len(file_paths) == n_files:\n",
    "        break\n",
    "\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895d5d8-1f33-4b55-b59d-4649f65db3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChairDataset(file_paths)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=2048, shuffle=True) #TODO: can specify num_workers\n",
    "\n",
    "n_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "# hidden_size = 500 \n",
    "# hidden_layer_act_func = \"ReLU\"\n",
    "# output_layer_act_func = None\n",
    "\n",
    "model = MLP(len(file_paths), 256, 256)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train(True) # prep model for training, needed for modules like Dropout\n",
    "\n",
    "now = datetime.now() \n",
    "now = now.strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0 # monitor training loss\n",
    "\n",
    "    for shape_idx, xyz, sdf in dataloader:\n",
    "        optimizer.zero_grad() \n",
    "        sdf_pred = model(shape_idx, xyz) \n",
    "        loss = criterion(torch.clamp(sdf_pred, -0.1, 0.1), torch.clamp(sdf, -0.1, 0.1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()*shape_idx.size(0) # update running training loss\n",
    "        \n",
    "    train_loss = train_loss/len(dataloader.dataset) # calculate average loss over one epoch\n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        torch.save(model.state_dict(), f'./models/multiple_shapes/' + now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e86457-4d9e-42b2-ba25-55c5e2e6af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'./models/multiple_shapes'\n",
    "loaded_model = MLP(len(file_paths), 256, 256)\n",
    "loaded_model.load_state_dict(torch.load(filename))\n",
    "loaded_model.eval()\n",
    "\n",
    "x = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "y = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "z = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "P = torch.from_numpy(P)\n",
    "\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * (0)\n",
    "\n",
    "volume = loaded_model(shape_idx_tensor,P).view(len(x), len(y), len(z)) #TODO: double check & compare numpy reshape vs pytorch view\n",
    "volume = volume.detach().numpy()\n",
    "\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69b9bd-5e77-4d92-a939-2b4fd3d9058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with ground truth\n",
    "mesh = trimesh.load(file_paths[0].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
