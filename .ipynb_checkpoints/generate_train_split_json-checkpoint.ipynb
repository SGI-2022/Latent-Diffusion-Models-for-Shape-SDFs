{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d72c5ec9-7f6e-4656-97dc-39bf26a40717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def load_files(all_file_or_not, n_files = 0):\n",
    "    file_paths = []\n",
    "    main_dir = '../latent_diffusion/data/03001627_sdfs/'\n",
    "\n",
    "    if all_file_or_not: # loading all files\n",
    "        n_files = 0\n",
    "        for sub_dir in os.scandir(main_dir):\n",
    "            if sub_dir.is_dir():\n",
    "                for file in os.listdir(main_dir + sub_dir.name):\n",
    "                    file_paths.append(main_dir + sub_dir.name + '/' + file) if file == \"sdf_samples.npz\" else None\n",
    "            n_files += 1\n",
    "            \n",
    "    else: # loading specific # of files\n",
    "        for sub_dir in os.scandir(main_dir):\n",
    "            if sub_dir.is_dir():\n",
    "                for file in os.listdir(main_dir + sub_dir.name):\n",
    "                    file_paths.append(main_dir + sub_dir.name + '/' + file) if file == \"sdf_samples.npz\" else None\n",
    "            if len(file_paths) == n_files:\n",
    "                break\n",
    "    \n",
    "    print(f'total # of files: {n_files}')\n",
    "    return file_paths\n",
    "\n",
    "# path example: latent_diffusion/latent_diffusion/data/03001627_sdfs/1006be65e7bc937e9141f9b58470d646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2084ad-02e1-4945-90e0-e78de1ad06a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of files: 6778\n",
      "6278\n"
     ]
    }
   ],
   "source": [
    "# load all filepaths\n",
    "filepaths = load_files(True)\n",
    "\n",
    "# load shape indices used for diffusion\n",
    "diffusion_model_dt = '10062022_011812' # used 6278 trainign shapes\n",
    "diffusion_log_filename = f'../latent_diffusion/diffusion logs & models/{diffusion_model_dt}/{diffusion_model_dt}.log'\n",
    "\n",
    "with open(diffusion_log_filename) as f:\n",
    "    f = f.readlines()\n",
    "\n",
    "for idx, line in enumerate(f):\n",
    "    if \"Shape indices\" in line:\n",
    "        shape_indices = line.split('=')[1].strip().strip('[').strip(']')\n",
    "\n",
    "shape_indices = shape_indices.split(', ')\n",
    "shape_indices = [int(shape_index) for shape_index in shape_indices]\n",
    "\n",
    "# get shapenames matching to the shape indices \n",
    "shape_names = []\n",
    "for shape_index in shape_indices:\n",
    "    shape_names.append(filepaths[shape_index].split('/')[4])\n",
    "\n",
    "# check if all shapenames are retrieved\n",
    "print(len(shape_names))\n",
    "\n",
    "# hard coding the dictionary keys according to our sdf files architecture\n",
    "dictionary = {\"data\": {\"03001627_sdfs\": shape_names}} \n",
    "\n",
    "import json\n",
    "json_object = json.dumps(dictionary, indent=2)\n",
    " \n",
    "with open(\"./examples/chairs/chairs_train.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b1cdfc9-affa-4880-bd01-635f87c89f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00284584  0.3508967   0.32118544]\n",
      " [ 0.3907591   0.4502787   0.39157248]\n",
      " [ 0.05056688  0.06562302  0.267699  ]\n",
      " ...\n",
      " [ 0.96285063  0.2036773   0.00703624]\n",
      " [ 0.28542417  0.7473609  -0.26989472]\n",
      " [ 0.6533466  -0.15837108 -0.5224776 ]]\n",
      "[[0.00147297]\n",
      " [0.00215678]\n",
      " [0.00245939]\n",
      " ...\n",
      " [0.53866714]\n",
      " [0.7109576 ]\n",
      " [0.26529077]]\n",
      "[[ 0.00284584  0.3508967   0.32118544  0.00147297]\n",
      " [ 0.3907591   0.4502787   0.39157248  0.00215678]\n",
      " [ 0.05056688  0.06562302  0.267699    0.00245939]\n",
      " ...\n",
      " [ 0.96285063  0.2036773   0.00703624  0.53866714]\n",
      " [ 0.28542417  0.7473609  -0.26989472  0.7109576 ]\n",
      " [ 0.6533466  -0.15837108 -0.5224776   0.26529077]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# path example: latent_diffusion/latent_diffusion/data/03001627_sdfs/1006be65e7bc937e9141f9b58470d646\n",
    "filename = \"../latent_diffusion/data/03001627_sdfs/1006be65e7bc937e9141f9b58470d646\"\n",
    "pos_npz = np.load(os.path.join(filename, 'pos_sdf_samples.npz'))\n",
    "neg_npz = np.load(os.path.join(filename, 'neg_sdf_samples.npz'))\n",
    "    \n",
    "    # if subsample is None:\n",
    "    #     return npz\n",
    "    \n",
    "    # concatenate xyz + sdf horizontally\n",
    "pos_points = pos_npz['points']\n",
    "print(pos_points)\n",
    "\n",
    "pos_sdfs = np.resize(pos_npz['sdf'], (len(pos_npz['sdf']), 1))\n",
    "print(pos_sdfs)\n",
    "pos_tensor = np.concatenate((pos_points, pos_sdfs), axis = 1)\n",
    "print(pos_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74858609-2140-44ea-95ac-b00b89ceed5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
