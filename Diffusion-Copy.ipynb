{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ecf8b7-8f0f-4fe3-a72d-4b59387f4cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3a1b24-d367-454d-9858-7df2415bd4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "import meshplot as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14b3049-ff4b-42ac-be68-7ad81b1b6e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "# 4 layer autodecoder MLP class for 10 shapes \n",
    "class MLP_4(nn.Module):\n",
    "    def __init__(self, n_shapes, shape_code_length, n_inner_nodes):\n",
    "        super(MLP_4, self).__init__()\n",
    "        self.shape_code_length = shape_code_length\n",
    "        self.shape_codes = nn.Embedding(n_shapes, shape_code_length, max_norm=0.01) # shape code as an embedding # TODO: take this outside \n",
    "        \n",
    "        self.linear1 = nn.Linear(3 + shape_code_length, n_inner_nodes) # (x, y, z) + shape code \n",
    "        self.linear2 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear3 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear4 = nn.Linear(n_inner_nodes, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, shape_idx, x):\n",
    "        shape_code = self.shape_codes(shape_idx.view(1, -1))\n",
    "        print(shape_code.shape)\n",
    "        shape_code = shape_code.view(-1, self.shape_code_length)\n",
    "        shape_code_with_xyz = torch.cat((x, shape_code), dim=1) # concatenate horizontally\n",
    "        \n",
    "        out = self.linear1(shape_code_with_xyz)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear4(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "filename = './models/autodecoder_08052022_073446' # trained for 10 shapes\n",
    "model = MLP_4(10, 256, 256)\n",
    "model.load_state_dict(torch.load(filename))\n",
    "\n",
    "shape_codes = model.state_dict()['shape_codes.weight']\n",
    "print(shape_codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7bb96d4-fff6-435f-b7f9-653bdc086158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPartial(nn.Module):\n",
    "    def __init__(self,shape_code_length, n_inner_nodes):\n",
    "        super(DecoderPartial, self).__init__()\n",
    "        self.shape_code_length = shape_code_length\n",
    "        self.linear1 = nn.Linear(3 + shape_code_length, n_inner_nodes) # (x, y, z) + shape code \n",
    "        self.linear2 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear3 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear4 = nn.Linear(n_inner_nodes, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,shape_code, x):\n",
    "        shape_code = shape_code.repeat([x.size()[0],1])\n",
    "        shape_code = shape_code.view(-1, self.shape_code_length)\n",
    "        shape_code_with_xyz = torch.cat((x, shape_code), dim=1) # concatenate horizontally\n",
    "        out = self.linear1(shape_code_with_xyz)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear4(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6968796e-12d3-4f7c-8dfd-c2b7836dba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderPartial(\n",
       "  (linear1): Linear(in_features=259, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (linear3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (linear4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = DecoderPartial(256,256)\n",
    "#mod_dict = mod.state_dict()\n",
    "mod.load_state_dict(torch.load(filename),strict=False)\n",
    "mod.eval()\n",
    "#for param_tensor in mod.state_dict():\n",
    "    #print(param_tensor, \"\\t\", mod.state_dict()[param_tensor])\n",
    "# 1. filter out unnecessary keys\n",
    "#pretrained_dict = {k: v for k, v in model.iteritems() if k in model_dict}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "#model_dict.load_state_dict(pretrained_dict) \n",
    "# 3. load the new state dict\n",
    "#model.load_state_dict(pretrained_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae4643-b821-492e-b5ec-1c8892e1b16d",
   "metadata": {},
   "source": [
    "## Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ee2e5a-18e4-4a43-b50b-2e60a422f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = shape_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3920c84b-7b37-41d7-8ea4-4c7bf94970e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f61531-577d-432e-9584-8c1f25516095",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(np.asarray(dataset))\n",
    "mean = np.mean(np.asarray(dataset))\n",
    "dataset = (dataset-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf71f5e-f078-4b84-a7bb-b1138d3d3f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_beta_schedule(schedule='linear', n_timesteps=1000, start=1e-5, end=1e-2):\n",
    "    if schedule == 'linear':\n",
    "        betas = torch.linspace(start, end, n_timesteps)\n",
    "    elif schedule == \"quad\":\n",
    "        betas = torch.linspace(start ** 0.5, end ** 0.5, n_timesteps) ** 2\n",
    "    elif schedule == \"sigmoid\":\n",
    "        betas = torch.linspace(-6, 6, n_timesteps)\n",
    "        betas = torch.sigmoid(betas) * (end - start) + start\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "094878bf-baa3-4e77-a287-68fce9f3c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 30000\n",
    "betas = make_beta_schedule(schedule='linear', n_timesteps=n_steps, start=1e-5, end=1e-2)\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, 0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d811fed-c538-48b6-8613-a240c274f992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas_bar_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b547a713-6657-4093-93ef-29e273fa018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(input, t, x):\n",
    "    shape = x.shape\n",
    "    out = torch.gather(input, 0, t.to(input.device))\n",
    "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
    "    return out.reshape(*reshape)\n",
    "def q_sample(x_0, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "    alphas_t = extract(alphas_bar_sqrt, t, x_0)\n",
    "    alphas_1_m_t = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    return (alphas_t * x_0 + alphas_1_m_t * noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cfa7a306-760f-4fd7-9c10-026532eac98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_6_q_max_list = []\n",
    "# for i in range(100):\n",
    "#     shape_6_q_max_list.append(q_sample(dataset[6,:], torch.tensor([10000-1])).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "55e42d6d-9e5a-4bcc-8f52-8693a81a5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean1 = np.mean(shape_6_q_max_list)\n",
    "# std1=np.std(shape_6_q_max_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105d505-0804-435d-9494-7a21120d9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "y = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "z = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "P = torch.from_numpy(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08e6f369-db75-4d85-ae8a-07720c52b4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a17a4bde0649ddb96527b26eeb079a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.498744…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5cbefdb77f41bb8a22163c56b7ee7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.495571…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa175bec40a0405481612b8512b39b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.498734…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f3cbec40e80>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inferring\n",
    "q_i = std*q_sample(dataset[5,:], torch.tensor([0]))+mean\n",
    "volume = mod(q_i,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces) # plot original shape\n",
    "\n",
    "\n",
    "# inferring\n",
    "q_i = std*q_sample(dataset[5,:], torch.tensor([1000-1]))+mean\n",
    "volume = mod(q_i,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces) # plot original shape\n",
    "\n",
    "\n",
    "# inferring\n",
    "q_i = std*q_sample(dataset[5,:], torch.tensor([5000-1]))+mean\n",
    "volume = mod(q_i,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces) # plot original shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ca7584b-ee1f-4e8b-bd95-fc4402bfa630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d77ddec7ff74639b5fb4eb783b8f781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.500711…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ecd48663964c42bdf74f88c637f0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.497913…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a8405810eb493e9a5d439077200334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.500980…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f3ccd741f10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# inferring\n",
    "q_i = std*q_sample(dataset[5,:], torch.tensor([10000-1]))+mean\n",
    "volume = mod(q_i,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces) # plot shape after forward process\n",
    "\n",
    "\n",
    "# inferring\n",
    "q_i = std*q_sample(dataset[5,:], torch.tensor([10000-1]))+mean\n",
    "volume = mod(q_i,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces) # plot shape after forward process\n",
    "\n",
    "\n",
    "# inferring\n",
    "q_i = std*q_sample(dataset[5,:], torch.tensor([10000-1]))+mean\n",
    "volume = mod(q_i,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces) # plot shape after forward process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f64d07-dfea-4881-92f7-b1ea58dd00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, n_steps, temb_ch):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        # self.embed = nn.Embedding(n_steps, num_out)\n",
    "        # self.embed.weight.data.uniform_()\n",
    "\n",
    "        self.temb_proj = torch.nn.Linear(temb_ch,\n",
    "                                         num_out)\n",
    "        self.nonlin = torch.nn.SiLU()\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "\n",
    "        out = self.temb_proj(self.nonlin(y)) + out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0057987-4977-4d78-a808-9c8cc05d633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, n_steps, ch=32, num_out=64):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.ch = ch\n",
    "        self.temb_ch = ch * 4\n",
    "        self.lin1 = ConditionalLinear(256,512, n_steps, self.temb_ch)\n",
    "        self.lin2 = ConditionalLinear(512, 512, n_steps, self.temb_ch)\n",
    "        self.lin3 = nn.Linear(512,256)\n",
    "\n",
    "\n",
    "        # timestep embedding\n",
    "        self.temb = nn.Sequential(\n",
    "            torch.nn.Linear(ch,\n",
    "                            self.temb_ch),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.Linear(self.temb_ch,\n",
    "                            self.temb_ch),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x, y): # x, t\n",
    "        y = get_timestep_embedding(y, self.ch)\n",
    "        temb = self.temb(y)\n",
    "        x = F.softplus(self.lin1(x, temb))\n",
    "        x = F.softplus(self.lin2(x, temb))\n",
    "        return self.lin3(x)\n",
    "\n",
    "def p_sample(model, x, t):\n",
    "    t = torch.tensor([t])\n",
    "    # Factor to the model output\n",
    "    eps_factor = ((1 - extract(alphas, t, x)) / extract(one_minus_alphas_bar_sqrt, t, x))\n",
    "    # Model output\n",
    "    eps_theta = model(x, t)\n",
    "    # Final values\n",
    "    mean = (1 / extract(alphas, t, x).sqrt()) * (x - (eps_factor * eps_theta))\n",
    "    # Generate z\n",
    "    z = torch.randn_like(x)\n",
    "    # Fixed sigma\n",
    "    sigma_t = extract(betas, t, x).sqrt()\n",
    "    sample = mean + sigma_t * z\n",
    "    return (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87dbb007-26ee-4fcc-8e5f-59686f3505a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_sample_loop(model, shape):\n",
    "    cur_x = torch.randn(shape)\n",
    "    x_seq = [cur_x]\n",
    "    for i in reversed(range(n_steps)):\n",
    "        cur_x = p_sample(model, cur_x, i)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d6da753-6933-4c00-85d1-2a1dc0027437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    This matches the implementation in Denoising Diffusion Probabilistic Models:\n",
    "    From Fairseq.\n",
    "    Build sinusoidal embeddings.\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
    "    emb = emb.to(device=timesteps.device)\n",
    "    emb = timesteps.float()[:, None] * emb[None, :]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2d8805f0-a0d2-4981-b1d8-66829d2c1d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 5, 256])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b=[]\n",
    "# for i in range(n_steps):\n",
    "#     f=torch.randn_like(dataset[:5,:])\n",
    "#     b.append(f[None,:,:])\n",
    "# e = torch.Tensor(n_steps,5, 256)\n",
    "# torch.cat(b, out=e)\n",
    "# e.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7ac70e7-4026-496a-9294-906ef3acffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788,  0.5684, -1.0845]])\n",
      "tensor([[ 1.5410, -0.2934, -2.1788,  0.5684, -1.0845]])\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(0)\n",
    "# print(torch.randn_like(torch.ones(1, 5)))\n",
    "# torch.manual_seed(0)\n",
    "# print(torch.randn_like(torch.ones(1, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "51b4b2c8-200e-43fe-bb84-d655ad91b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def noise_estimation_loss(model, x_0,noise_steps):\n",
    "def noise_estimation_loss(model, x_0):\n",
    "\n",
    "    batch_size = x_0.shape[0]\n",
    "    # Select a random step for each example\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2 + 1,)) # pick (batch_size//2+1) number of rand integers in bw 0 and n_steps\n",
    "    t = torch.cat([t, n_steps - t - 1], dim=0)[:batch_size].long() # pick other time index symmetrically\n",
    "    # x0 multiplier\n",
    "    a = extract(alphas_bar_sqrt, t, x_0)\n",
    "    # eps multiplier\n",
    "    am1 = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "    e = torch.randn_like(x_0)\n",
    "    # e = noise_steps[t, :,:]\n",
    "    # model input\n",
    "    x = x_0 * a + e * am1\n",
    "    output = model(x, t)\n",
    "    return (e - output).square().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7fcf6b0a-a25a-4641-97bb-9922611a27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA(object):\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "085c0990-6265-4e77-9212-0b6d0378159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalModel(n_steps)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, betas = (0.9, 0.9), eps=1e-07)\n",
    "#dataset = torch.tensor(data.T).float()\n",
    "dataset = dataset.float()\n",
    "# Create EMA model\n",
    "ema = EMA(0.9)\n",
    "ema.register(model)\n",
    "# Batch size\n",
    "batch_size = 5\n",
    "\n",
    "now = datetime.now() \n",
    "now = now.strftime(\"%m%d%Y_%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "650855a5-11d4-456e-8a24-1f35b27558db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# now = datetime.now() \n",
    "# now = now.strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "# #log loss\n",
    "# f = open(f'./diffusion logs/{now}.csv','a')\n",
    "# f.write(str(loss)+'\\n') \n",
    "# f.close()\n",
    "\n",
    "# #load loss and plot\n",
    "# df = pd.read_csv('./diffusion logs/test.csv', header=None)\n",
    "# df.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "363266d6-57f2-4708-9b59-17611e1f5480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0017, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0040, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0534, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0016, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0022, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "f = open(f'./diffusion logs/{now}.csv','a')\n",
    "\n",
    "for t in range(100000):\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(dataset.size()[0])\n",
    "    for i in range(0, dataset.size()[0], batch_size):\n",
    "        # Retrieve current batch\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x = dataset[indices]\n",
    "        # Compute the loss.\n",
    "        # loss = noise_estimation_loss(model, batch_x,e)\n",
    "        loss = noise_estimation_loss(model, batch_x)\n",
    "        # Before the backward pass, zero all of the network gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass: compute gradient of the loss with respect to parameters\n",
    "        loss.backward()\n",
    "        # Perform gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "        # Calling the step function to update the parameters\n",
    "        optimizer.step()\n",
    "        # Update the exponential moving average\n",
    "        ema.update(model)\n",
    "    # Print loss\n",
    "    if (t % 10 == 0):\n",
    "        f.write(str(loss.item())+'\\n') \n",
    "    if (t % 100 == 0):\n",
    "        torch.save(model.state_dict(), f'./diffusion logs/conditional model_{now}')\n",
    "        print(loss)\n",
    "    if loss < 0.0012:\n",
    "        torch.save(model.state_dict(), f'./diffusion logs/conditional model_{now}')\n",
    "        break\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895335c0-d790-45e9-b362-435243c5fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0541a07c-1d2b-4d9a-911a-52ac47fe4f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0011, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dc2f922-b68e-430d-9e99-d0439e1c1b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97c73da79c141f188694b5269960fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.498733…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47640336fbad4e6683b691bd02c37e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(50.034333…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5801af4cc1493794117ec0abcb7cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(48.498877…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f3cd72c3af0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './diffusion logs/conditional model_08182022_205351'\n",
    "model = ConditionalModel(n_steps)\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "x_0 = dataset\n",
    "shape_idx = 5\n",
    "timestep = 30000-1\n",
    "\n",
    "\n",
    "# x = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# y = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# z = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "# P = torch.from_numpy(P)\n",
    "\n",
    "\n",
    "original_code_standardized=std*x_0[shape_idx,:]+mean\n",
    "volume = mod(original_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "noised_code = q_sample(x_0[shape_idx, :], torch.tensor([timestep]))\n",
    "noised_code_standardized = std*noised_code+mean\n",
    "volume = mod(noised_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "079cc810-6991-405b-a844-8bf53218c5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbc2d6359534be78f4591888dee2615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(50.998323…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7204d774c84439a93487d42fb1787d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(50.495885…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b5b3a4a8b3426cab477bfab60dec2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.984013…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aca0f394d3b495f9c179eda91f09585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.094991…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9163bebf5cf4ca39bf688b87ee7d8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(50.684421…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f3ccd688100>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdab2824-1640-4dc0-8ef6-e69308e8a602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf329122b2614ec4b87de97f37d690fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.498733…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd4e4a1a9b043d3b37a5272fd075ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.499081…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cd86af0da74630ac6acbf23ba81eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(47.513990…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ea8a9677934080b296c9c92c70ac03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(48.005763…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f3cd72adb80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './diffusion logs/conditional model_08182022_205351'\n",
    "model = ConditionalModel(n_steps)\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "x_0 = dataset\n",
    "shape_idx = 5\n",
    "timestep = 10000-1\n",
    "\n",
    "\n",
    "# x = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# y = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# z = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "# P = torch.from_numpy(P)\n",
    "\n",
    "original_code_standardized=std*x_0[shape_idx,:]+mean\n",
    "volume = mod(original_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('original')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "noised_code = q_sample(x_0[shape_idx, :], torch.tensor([timestep]))\n",
    "noised_code_standardized = std*noised_code+mean\n",
    "volume = mod(noised_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('noisy')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('denoised')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('denoised')\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e13a059-2f62-423b-91da-21d7065bf7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f957703f5e4f42ff811579969ffd4694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.219427…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ed1982e3d846e893ba9ffb74166e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.920176…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoised 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a705e669b48f4e378b37a9739f8bd462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.040920…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoised 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab961381d034a1ab274c4f919a132a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(48.992958…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoised 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cd08b45f094c588b910e2794d41f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(50.500508…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f3ccdd7aa60>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './diffusion logs/conditional model_08182022_205351'\n",
    "model = ConditionalModel(n_steps)\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "x_0 = dataset\n",
    "shape_idx = 0\n",
    "shape_idx2 =2\n",
    "timestep = 5000\n",
    "\n",
    "\n",
    "# x = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# y = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# z = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "# P = torch.from_numpy(P)\n",
    "\n",
    "q = (x_0[shape_idx,:] + x_0[shape_idx2,:])/2\n",
    "\n",
    "\n",
    "original_code_standardized=std*q+mean\n",
    "volume = mod(original_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('original')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "noised_code = q_sample(q, torch.tensor([timestep]))\n",
    "noised_code_standardized = std*noised_code+mean\n",
    "volume = mod(noised_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('noisy')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('denoised 1')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('denoised 2')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('denoised 3')\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3d7a4d5-a0bb-4f2f-8a72-eb7a3ee0699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fd3f88908448f7b9347e50b029a119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.498733…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b05f8e6c174bf3bfae3acad117e9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.007408…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8222fb0cbbe4fe7b3a00bf2e2e2fa14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.473046…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denoised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b180710abb5473f9bec6b61b9489e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(49.500925…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f3cbe8ea760>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './diffusion logs/conditional model_08182022_205351'\n",
    "model = ConditionalModel(n_steps)\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "x_0 = dataset\n",
    "shape_idx = 5\n",
    "timestep = 5000\n",
    "\n",
    "\n",
    "# x = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# y = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# z = np.linspace(-1, 1, 100, dtype=np.float32)\n",
    "# P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "# P = torch.from_numpy(P)\n",
    "\n",
    "\n",
    "original_code_standardized=std*x_0[shape_idx,:]+mean\n",
    "volume = mod(original_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('original')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "noised_code = q_sample(x_0[shape_idx, :], torch.tensor([timestep]))\n",
    "noised_code_standardized = std*noised_code+mean\n",
    "volume = mod(noised_code_standardized, P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('noisy')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('denoised')\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "\n",
    "\n",
    "denoised_code = noised_code\n",
    "for i in reversed(range(timestep)):\n",
    "    denoised_code = p_sample(model, denoised_code, i)\n",
    "denoised_code_standardized = std*denoised_code+mean\n",
    "volume = mod(denoised_code_standardized,P).view(len(x), len(y), len(z)) \n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "print('denoised')\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b30bc4-2b32-4262-ae43-fcecd4278c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for constant random vector\n",
    "\n",
    "x_0 = dataset[:5,:]\n",
    "q=std*x_0[0,:]+mean\n",
    "volume = mod(q,P).view(len(x), len(y), len(z)) \n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "t=torch.tensor([600])\n",
    "a = extract(alphas_bar_sqrt, t, x_0)\n",
    "# eps multiplier\n",
    "am1 = extract(one_minus_alphas_bar_sqrt, t, x_0)\n",
    "#e = torch.randn_like(x_0)\n",
    "# model input\n",
    "xx = x_0 * a + e * am1\n",
    "q=std*xx[0,:]+mean\n",
    "volume = mod(q,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)\n",
    "\n",
    "#output = model(x, t)\n",
    "cur_x = xx\n",
    "for i in reversed(range(600)):\n",
    "    #for j in range(10):\n",
    "    cur_x = p_sample(model, cur_x, i)\n",
    "    #x_seq.append(cur_x)\n",
    "q=std*cur_x[0,:]+mean\n",
    "volume = mod(q,P).view(len(x), len(y), len(z)) \n",
    "\n",
    "# marching cube to visualize\n",
    "volume = volume.detach().numpy()\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
