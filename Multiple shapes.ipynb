{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23d4aee-3f90-4bd4-9722-a5a81ee25680",
   "metadata": {},
   "source": [
    "## Standardized code base for multiple shapes MLP model (Audodecoder model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9908f01-3df0-49c0-9648-a5f1823bd13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "from skimage import measure\n",
    "import meshplot as mp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72744b0a-cdbc-4f0d-8ace-0057a6cbee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: clamping\n",
    "#TODO: tanh() at the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679ef0f-9da5-40ab-a8b2-a2ab2218c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag shape index to each x=xyz, y=sdf\n",
    "# horizontally concatenate for multiple chapes\n",
    "# returns shape index, x=xyz (1 by 3), y=sdf\n",
    "class ChairDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        for idx, file_path in enumerate(file_paths): #TODO: move to getitem\n",
    "            training_set = np.load(file_path)\n",
    "            points = training_set['points']\n",
    "            points = torch.from_numpy(points.astype(np.float32)) #TODO: dypte precision is lost??\n",
    "            idx_tensor = torch.ones((points.shape[0], 1), dtype=torch.int) * (idx) # 0 based indexing shapes\n",
    "            \n",
    "            sdf = training_set['sdf']\n",
    "            sdf = torch.from_numpy(sdf.astype(np.float32)) \n",
    "            sdf = sdf.view(sdf.shape[0], 1)\n",
    "            \n",
    "            n_samples = sdf.shape[0] \n",
    "\n",
    "            if idx == 0:\n",
    "                self.shape_idx = idx_tensor\n",
    "                self.x = points\n",
    "                self.y = sdf\n",
    "                self.n_samples = n_samples\n",
    "            else:\n",
    "                self.shape_idx = torch.cat((self.shape_idx, idx_tensor), dim = 0) # concatenate vertically\n",
    "                self.x = torch.cat((self.x, points), dim = 0) #concatenate vertically\n",
    "                self.y = torch.cat((self.y, sdf), dim = 0) #concatenate vertically\n",
    "                self.n_samples += n_samples\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.shape_idx[index], self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd06d3-6bbd-4a1b-86e6-d69e5c0d33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "\n",
    "# dataset = ChairDataset(['../data/03001627_sdfs/1006be65e7bc937e9141f9b58470d646/sdf_samples.npz',\n",
    "#                         '../data/03001627_sdfs/1007e20d5e811b308351982a6e40cf41/sdf_samples.npz',\n",
    "#                         '../data/03001627_sdfs/100b18376b885f206ae9ad7e32c4139d/sdf_samples.npz']) # TODO: auto select 10 from the directory\n",
    "# dataloader = DataLoader(dataset=dataset, batch_size=5, shuffle=True) #TODO: can specify num_workers\n",
    "\n",
    "# TrainingSet = np.load('../data/03001627_sdfs/1007e20d5e811b308351982a6e40cf41/sdf_samples.npz')\n",
    "# points = TrainingSet['points']\n",
    "# sdf = TrainingSet['sdf']\n",
    "# print(points)\n",
    "# print(sdf)\n",
    "\n",
    "# first_dataset_first_data = dataset[50000]\n",
    "# idx, x, y = first_dataset_first_data\n",
    "# print(idx, x, y)\n",
    "\n",
    "# check: print one batch\n",
    "# dataiter = iter(dataloader)\n",
    "# data = dataiter.next() \n",
    "# shape_idx, xyz, sdf = data\n",
    "# print(shape_idx, xyz, sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fb065-53e1-4cec-a572-072e974f445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_shapes, shape_code_length, n_inner_nodes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.shape_code_length = shape_code_length\n",
    "        self.shape_codes = nn.Embedding(n_shapes, shape_code_length, max_norm=0.01) # shape code as an embedding # TODO: take this outside \n",
    "        self.linear1 = nn.Linear(3 + shape_code_length, n_inner_nodes) # (x, y, z) + shape code \n",
    "        self.linear2 = nn.Linear(n_inner_nodes, n_inner_nodes)\n",
    "        self.linear3 = nn.Linear(n_inner_nodes, 1) # output a SDF value\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, shape_idx, x):\n",
    "        shape_code = self.shape_codes(shape_idx.view(1, -1))\n",
    "        shape_code = shape_code.view(-1, self.shape_code_length)\n",
    "        shape_code_with_xyz = torch.cat((x, shape_code), dim=1) # concatenate horizontally\n",
    "        \n",
    "        out = self.linear1(shape_code_with_xyz)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b82d41-9f8a-4846-970b-6df39464bebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/03001627_sdfs/4e664dae1bafe49f19fb4103277a6b93/sdf_samples.npz', '../data/03001627_sdfs/65840c85162994d990de7d30a74bbb6b/sdf_samples.npz', '../data/03001627_sdfs/c7ae4cc12a7bc2581fa16f9a5527bb27/sdf_samples.npz', '../data/03001627_sdfs/e9e224bc0a0787d8320f10afdfbaa18/sdf_samples.npz', '../data/03001627_sdfs/68c7f82dd1e1634d9338458f802f5ad7/sdf_samples.npz', '../data/03001627_sdfs/58a7b826ed562b7bb0957d845ac33749/sdf_samples.npz', '../data/03001627_sdfs/e4c866b5dd958cd0803d0f5bac2abe4c/sdf_samples.npz', '../data/03001627_sdfs/9a91a491a9e74ab132c074e5313866f2/sdf_samples.npz', '../data/03001627_sdfs/670b6b7d3fe6e4a77c5a5393686fdcfc/sdf_samples.npz', '../data/03001627_sdfs/2d701c588b3bbbc458c88d30f502a452/sdf_samples.npz']\n"
     ]
    }
   ],
   "source": [
    "n_files = 10\n",
    "file_paths = []\n",
    "main_dir = '../data/03001627_sdfs/'\n",
    "for sub_dir in os.scandir(main_dir):\n",
    "    if sub_dir.is_dir():\n",
    "        for file in os.listdir(main_dir + sub_dir.name):\n",
    "            file_paths.append(main_dir + sub_dir.name + '/' + file) if file.endswith(\"sdf_samples.npz\") else None\n",
    "    if len(file_paths) == n_files:\n",
    "        break\n",
    "\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e65a0-042d-4433-a812-037aa5c1f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChairDataset(file_paths)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=2048, shuffle=True) #TODO: can specify num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a979f-1a0e-4caa-ad35-96e6aee0b1b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     16\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;66;03m# monitor training loss\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shape_idx, xyz, sdf \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     19\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[1;32m     20\u001b[0m         sdf_pred \u001b[38;5;241m=\u001b[39m model(shape_idx, xyz) \n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mChairDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "# hidden_size = 500 \n",
    "# hidden_layer_act_func = \"ReLU\"\n",
    "# output_layer_act_func = None\n",
    "\n",
    "model = MLP(len(file_paths), 256, 256)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train(True) # prep model for training, needed for modules like Dropout\n",
    "\n",
    "now = datetime.now() \n",
    "now = now.strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0 # monitor training loss\n",
    "\n",
    "    for shape_idx, xyz, sdf in dataloader:\n",
    "        optimizer.zero_grad() \n",
    "        sdf_pred = model(shape_idx, xyz) \n",
    "        loss = criterion(torch.clamp(sdf_pred, -0.1, 0.1), torch.clamp(sdf, -0.1, 0.1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()*shape_idx.size(0) # update running training loss\n",
    "        \n",
    "    train_loss = train_loss/len(dataloader.dataset) # calculate average loss over one epoch\n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        torch.save(model.state_dict(), f'./models/multiple_shapes/' + now)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46edf832-8560-409f-8a52-77ebe0a7a7c0",
   "metadata": {},
   "source": [
    "Epoch: 1 \tTraining Loss: 0.000281\n",
    "Epoch: 11 \tTraining Loss: 0.000051\n",
    "Epoch: 21 \tTraining Loss: 0.000040\n",
    "Epoch: 31 \tTraining Loss: 0.000025\n",
    "Epoch: 41 \tTraining Loss: 0.000027\n",
    "Epoch: 51 \tTraining Loss: 0.000021\n",
    "Epoch: 61 \tTraining Loss: 0.000021\n",
    "Epoch: 71 \tTraining Loss: 0.000021\n",
    "Epoch: 81 \tTraining Loss: 0.000019\n",
    "Epoch: 91 \tTraining Loss: 0.000017\n",
    "Epoch: 101 \tTraining Loss: 0.000016\n",
    "Epoch: 111 \tTraining Loss: 0.000014\n",
    "Epoch: 121 \tTraining Loss: 0.000013\n",
    "Epoch: 131 \tTraining Loss: 0.000013\n",
    "Epoch: 141 \tTraining Loss: 0.000012\n",
    "Epoch: 151 \tTraining Loss: 0.000010\n",
    "Epoch: 161 \tTraining Loss: 0.000011\n",
    "Epoch: 171 \tTraining Loss: 0.000011\n",
    "Epoch: 181 \tTraining Loss: 0.000009\n",
    "Epoch: 191 \tTraining Loss: 0.000009\n",
    "Epoch: 201 \tTraining Loss: 0.000008\n",
    "Epoch: 211 \tTraining Loss: 0.000009\n",
    "Epoch: 221 \tTraining Loss: 0.000008\n",
    "Epoch: 231 \tTraining Loss: 0.000009\n",
    "Epoch: 241 \tTraining Loss: 0.000008\n",
    "Epoch: 251 \tTraining Loss: 0.000009\n",
    "Epoch: 261 \tTraining Loss: 0.000007\n",
    "Epoch: 271 \tTraining Loss: 0.000007\n",
    "Epoch: 281 \tTraining Loss: 0.000007\n",
    "Epoch: 291 \tTraining Loss: 0.000007\n",
    "Epoch: 301 \tTraining Loss: 0.000007\n",
    "Epoch: 311 \tTraining Loss: 0.000007\n",
    "Epoch: 321 \tTraining Loss: 0.000007\n",
    "Epoch: 331 \tTraining Loss: 0.000006\n",
    "Epoch: 341 \tTraining Loss: 0.000007\n",
    "Epoch: 351 \tTraining Loss: 0.000006\n",
    "Epoch: 361 \tTraining Loss: 0.000006\n",
    "Epoch: 371 \tTraining Loss: 0.000007\n",
    "Epoch: 381 \tTraining Loss: 0.000006\n",
    "Epoch: 391 \tTraining Loss: 0.000006\n",
    "Epoch: 401 \tTraining Loss: 0.000006\n",
    "Epoch: 411 \tTraining Loss: 0.000006\n",
    "Epoch: 421 \tTraining Loss: 0.000006\n",
    "Epoch: 431 \tTraining Loss: 0.000006\n",
    "Epoch: 441 \tTraining Loss: 0.000005\n",
    "Epoch: 451 \tTraining Loss: 0.000006\n",
    "Epoch: 461 \tTraining Loss: 0.000005\n",
    "Epoch: 471 \tTraining Loss: 0.000006\n",
    "Epoch: 481 \tTraining Loss: 0.000005\n",
    "Epoch: 491 \tTraining Loss: 0.000005\n",
    "Epoch: 501 \tTraining Loss: 0.000005\n",
    "Epoch: 511 \tTraining Loss: 0.000005\n",
    "Epoch: 521 \tTraining Loss: 0.000005\n",
    "Epoch: 531 \tTraining Loss: 0.000005\n",
    "Epoch: 541 \tTraining Loss: 0.000005\n",
    "Epoch: 551 \tTraining Loss: 0.000005\n",
    "Epoch: 561 \tTraining Loss: 0.000005\n",
    "Epoch: 571 \tTraining Loss: 0.000005\n",
    "Epoch: 581 \tTraining Loss: 0.000005\n",
    "Epoch: 591 \tTraining Loss: 0.000005\n",
    "Epoch: 601 \tTraining Loss: 0.000005\n",
    "Epoch: 611 \tTraining Loss: 0.000005\n",
    "Epoch: 621 \tTraining Loss: 0.000005\n",
    "Epoch: 631 \tTraining Loss: 0.000005\n",
    "Epoch: 651 \tTraining Loss: 0.000005\n",
    "Epoch: 661 \tTraining Loss: 0.000005\n",
    "Epoch: 671 \tTraining Loss: 0.000005\n",
    "Epoch: 681 \tTraining Loss: 0.000005\n",
    "Epoch: 691 \tTraining Loss: 0.000005\n",
    "Epoch: 701 \tTraining Loss: 0.000005\n",
    "Epoch: 711 \tTraining Loss: 0.000004\n",
    "Epoch: 721 \tTraining Loss: 0.000005\n",
    "Epoch: 731 \tTraining Loss: 0.000004\n",
    "Epoch: 741 \tTraining Loss: 0.000004\n",
    "Epoch: 751 \tTraining Loss: 0.000004\n",
    "Epoch: 761 \tTraining Loss: 0.000004\n",
    "Epoch: 771 \tTraining Loss: 0.000005\n",
    "Epoch: 781 \tTraining Loss: 0.000004\n",
    "Epoch: 791 \tTraining Loss: 0.000004\n",
    "Epoch: 801 \tTraining Loss: 0.000004\n",
    "Epoch: 811 \tTraining Loss: 0.000004\n",
    "Epoch: 821 \tTraining Loss: 0.000004\n",
    "Epoch: 831 \tTraining Loss: 0.000004\n",
    "Epoch: 841 \tTraining Loss: 0.000004\n",
    "Epoch: 851 \tTraining Loss: 0.000004\n",
    "Epoch: 861 \tTraining Loss: 0.000004\n",
    "Epoch: 871 \tTraining Loss: 0.000004\n",
    "Epoch: 881 \tTraining Loss: 0.000004\n",
    "Epoch: 891 \tTraining Loss: 0.000004\n",
    "Epoch: 901 \tTraining Loss: 0.000004\n",
    "Epoch: 911 \tTraining Loss: 0.000004\n",
    "Epoch: 921 \tTraining Loss: 0.000004\n",
    "Epoch: 931 \tTraining Loss: 0.000005\n",
    "Epoch: 941 \tTraining Loss: 0.000004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d661fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daef9de1c2384155afddd528c4d97700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(77.569122…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f2322663a00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f'./models/multiple_shapes'\n",
    "loaded_model = MLP(len(file_paths), 256, 256)\n",
    "loaded_model.load_state_dict(torch.load(filename))\n",
    "loaded_model.eval()\n",
    "\n",
    "x = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "y = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "z = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "P = torch.from_numpy(P)\n",
    "\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * (0)\n",
    "\n",
    "volume = loaded_model(shape_idx_tensor,P).view(len(x), len(y), len(z)) #TODO: double check & compare numpy reshape vs pytorch view\n",
    "volume = volume.detach().numpy()\n",
    "\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8e138-5b48-4309-881a-0c44d7db55af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paulaugguerrero_gmail_com/miniconda3/lib/python3.9/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"float32\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  warnings.warn(\n",
      "/home/paulaugguerrero_gmail_com/miniconda3/lib/python3.9/site-packages/traittypes/traittypes.py:97: UserWarning: Given trait value dtype \"uint32\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3644f5ba19444da787e33d656711855a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f232104f220>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with ground truth\n",
    "mesh = trimesh.load(file_paths[0].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21dcda-69a2-40af-98cf-be570f0d9b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec29110e92a40c19793778dd720c83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(79.400351…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f232103ca00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "y = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "z = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "P = torch.from_numpy(P)\n",
    "\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * (2)\n",
    "\n",
    "volume = model(shape_idx_tensor,P).view(len(x), len(y), len(z)) #TODO: double check & compare numpy reshape vs pytorch view\n",
    "volume = volume.detach().numpy()\n",
    "\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee7fc3-1e41-43cd-9c32-fefadf596bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc7962f5bed4941a112709d124579ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f22f90c2c40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with ground truth\n",
    "mesh = trimesh.load(file_paths[2].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631539ca-dd6c-43e2-b4e0-0c5ffba21ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2959aac567f845afaed5d92670917c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(69.182769…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f232103c310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "y = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "z = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "P = torch.from_numpy(P)\n",
    "\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * (8)\n",
    "\n",
    "volume = model(shape_idx_tensor,P).view(len(x), len(y), len(z)) #TODO: double check & compare numpy reshape vs pytorch view\n",
    "volume = volume.detach().numpy()\n",
    "\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4d226-f3f7-418e-8df5-8de4aac52952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3153f99fd5974780a71c99857c4f5b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f22f81e8160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with ground truth\n",
    "mesh = trimesh.load(file_paths[8].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b67529-4fa5-4455-b66b-fcf9cc2061de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28d1f81b3204c479e22cca1e9bfca64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(80.365926…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f232104ffd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "y = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "z = np.linspace(-1, 1, 150, dtype=np.float32)\n",
    "P = np.vstack(np.meshgrid(x,y,z)).reshape(3,-1).T  # format: [[x1, y1, z1], [x1, y1, z2], [] ...]\n",
    "P = torch.from_numpy(P)\n",
    "\n",
    "shape_idx_tensor = torch.ones((P.shape[0], 1), dtype=torch.int) * (7)\n",
    "\n",
    "volume = model(shape_idx_tensor,P).view(len(x), len(y), len(z)) #TODO: double check & compare numpy reshape vs pytorch view\n",
    "volume = volume.detach().numpy()\n",
    "\n",
    "verts, faces, normals, values = measure.marching_cubes(volume, 0)\n",
    "mp.plot(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1d6fa-6522-41ca-95a0-a4fe0a8f40a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446a743f21404614b79514854caa1c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f232104f8b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with ground truth\n",
    "mesh = trimesh.load(file_paths[7].split('sdf_samples.npz')[0] + 'mesh.obj')\n",
    "mp.plot(mesh.vertices, mesh.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db92a5-8b60-4ccc-8c8e-e5a82965bd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
